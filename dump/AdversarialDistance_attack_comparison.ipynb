{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installation and Repository cloning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-27T07:37:46.595135Z",
     "iopub.status.busy": "2024-05-27T07:37:46.594237Z",
     "iopub.status.idle": "2024-05-27T07:38:27.984603Z",
     "shell.execute_reply": "2024-05-27T07:38:27.983185Z",
     "shell.execute_reply.started": "2024-05-27T07:37:46.595102Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Der Befehl \"{sys.executable}\" ist entweder falsch geschrieben oder\n",
      "konnte nicht gefunden werden.\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\admin\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install numpy==1.20.0\n",
    "!pip install adversarial-robustness-toolbox -U --quiet\n",
    "!pip install multiprocess --quiet\n",
    "!pip install importlib --quiet\n",
    "!pip install advertorch --quiet\n",
    "#!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-27T07:48:23.754084Z",
     "iopub.status.busy": "2024-05-27T07:48:23.753216Z",
     "iopub.status.idle": "2024-05-27T07:48:23.759776Z",
     "shell.execute_reply": "2024-05-27T07:48:23.758824Z",
     "shell.execute_reply.started": "2024-05-27T07:48:23.754052Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from advertorch_examples.models import get_cifar10_wrn28_widen_factor\n",
    "\n",
    "import numba\n",
    "numba.__version__\n",
    "\n",
    "import importlib\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "from PIL import Image, ImageDraw, ImageFont, ImageOps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Adversarial Attack Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and Prepare CIFAR-10 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-27T07:48:25.353034Z",
     "iopub.status.busy": "2024-05-27T07:48:25.352439Z",
     "iopub.status.idle": "2024-05-27T07:48:25.360057Z",
     "shell.execute_reply": "2024-05-27T07:48:25.358935Z",
     "shell.execute_reply.started": "2024-05-27T07:48:25.352998Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_dataset(dataset_split: int):\n",
    "  # Load CIFAR-10 dataset using torchvision\n",
    "  transform = transforms.Compose([transforms.ToTensor()])\n",
    "  testset = datasets.CIFAR10(root='./data/cifar', train=False, download=True, transform=transform)\n",
    "\n",
    "  # Truncated testset for experiments and ablations\n",
    "  truncated_testset, _ = torch.utils.data.random_split(testset,\n",
    "                                                      [dataset_split, len(testset) - dataset_split],\n",
    "                                                      generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "  # Extract data and labels from torchvision dataset\n",
    "  xtest = torch.stack([data[0] for data in truncated_testset])\n",
    "  ytest = torch.tensor([data[1] for data in truncated_testset])\n",
    "\n",
    "  return xtest, ytest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and Prepare WideResNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-27T07:48:26.196050Z",
     "iopub.status.busy": "2024-05-27T07:48:26.195610Z",
     "iopub.status.idle": "2024-05-27T07:48:26.377816Z",
     "shell.execute_reply": "2024-05-27T07:48:26.376880Z",
     "shell.execute_reply.started": "2024-05-27T07:48:26.196010Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp/ipykernel_5000/2359150776.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(PATH)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on CUDA device 2 but torch.cuda.device_count() is 1. Please use torch.load with map_location to map your storages to an existing device.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5000/2359150776.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataParallel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mPATH\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf'./models/pretrained_models/{modeltype}'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1112\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_get_wo_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m         return _legacy_load(\n\u001b[0m\u001b[0;32m   1115\u001b[0m             \u001b[0mopened_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_legacy_load\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1346\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mUnpicklerWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1347\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1348\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1350\u001b[0m     \u001b[0mdeserialized_storage_keys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[1;34m(saved_id)\u001b[0m\n\u001b[0;32m   1279\u001b[0m                     \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mStorage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUntypedStorage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1280\u001b[0m                     \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_torch_load_uninitialized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1281\u001b[1;33m                     \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1282\u001b[0m                 \u001b[1;31m# TODO: Once we decide to break serialization FC, we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1283\u001b[0m                 \u001b[1;31m# stop wrapping with TypedStorage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[1;34m(storage, location)\u001b[0m\n\u001b[0;32m    412\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 414\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    415\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_deserialize\u001b[1;34m(backend_name, obj, location)\u001b[0m\n\u001b[0;32m    389\u001b[0m         \u001b[0mbackend_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_privateuse1_backend_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbackend_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 391\u001b[1;33m         \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackend_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    392\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_validate_device\u001b[1;34m(location, backend_name)\u001b[0m\n\u001b[0;32m    370\u001b[0m         \u001b[0mdevice_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdevice_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdevice_index\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mdevice_count\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 372\u001b[1;33m             raise RuntimeError(f'Attempting to deserialize object on {backend_name.upper()} device '\n\u001b[0m\u001b[0;32m    373\u001b[0m                                \u001b[1;34mf'{device_index} but torch.{backend_name}.device_count() is {device_count}. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    374\u001b[0m                                \u001b[1;34m'Please use torch.load with map_location to map your storages '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Attempting to deserialize object on CUDA device 2 but torch.cuda.device_count() is 1. Please use torch.load with map_location to map your storages to an existing device."
     ]
    }
   ],
   "source": [
    "import models.wideresnet as wideresnet\n",
    "\n",
    "modeltype = 'adversarial2.pth'\n",
    "\n",
    "if modeltype == 'standard.pth':\n",
    "    net = wideresnet.WideResNet_28_4(10, 'CIFAR10', normalized=True, block=wideresnet.WideBasic, activation_function='relu')\n",
    "    state_dict = \"model_state_dict\"\n",
    "elif modeltype == 'robust.pth':\n",
    "    #self trained with massive random data augmentation and JSD consistency loss, but no adversarial objective\n",
    "    net = wideresnet.WideResNet_28_4(10, 'CIFAR10', normalized=True, block=wideresnet.WideBasic, activation_function='silu')\n",
    "    state_dict = \"model_state_dict\"\n",
    "elif modeltype == 'adversarial1.pt':\n",
    "    #from https://github.com/BorealisAI/mma_training/tree/master/trained_models/cifar10-Linf-MMA-20-sd0\n",
    "    net = get_cifar10_wrn28_widen_factor(4)\n",
    "    state_dict = \"model\"\n",
    "elif modeltype == 'adversarial2.pth':\n",
    "    #https://github.com/inspire-group/hydra (adv. training 0%pruning)\n",
    "    net = wideresnet.WideResNet_28_4(10, 'CIFAR10', normalized=True, block=wideresnet.WideBasic, activation_function='relu')\n",
    "    state_dict = \"model\"\n",
    "\n",
    "net = torch.nn.DataParallel(net)\n",
    "PATH = f'./models/pretrained_models/{modeltype}'\n",
    "model = torch.load(PATH)\n",
    "net.load_state_dict(model[state_dict], strict=False)\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.01)\n",
    "\n",
    "# Initialize PyTorchClassifier for ART\n",
    "classifier = PyTorchClassifier(model=net,\n",
    "                               loss=criterion,\n",
    "                               optimizer=optimizer,\n",
    "                               input_shape=(3, 32, 32),\n",
    "                               nb_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.attacks.evasion import (FastGradientMethod,\n",
    "                                 ProjectedGradientDescentPyTorch,\n",
    "                                 AutoAttack,\n",
    "                                 AutoProjectedGradientDescent,\n",
    "                                 AutoConjugateGradient,\n",
    "                                 CarliniLInfMethod,\n",
    "                                 CarliniL2Method,\n",
    "                                 NewtonFool,\n",
    "                                 DeepFool,\n",
    "                                 ElasticNet,\n",
    "                                 FrameSaliencyAttack,\n",
    "                                 HopSkipJump,\n",
    "                                 BasicIterativeMethod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adversarial Attack Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-27T07:48:27.132718Z",
     "iopub.status.busy": "2024-05-27T07:48:27.132363Z",
     "iopub.status.idle": "2024-05-27T07:48:27.146971Z",
     "shell.execute_reply": "2024-05-27T07:48:27.145960Z",
     "shell.execute_reply.started": "2024-05-27T07:48:27.132687Z"
    }
   },
   "outputs": [],
   "source": [
    "class AdversarialAttacks:\n",
    "  def __init__(self, classifier, epsilon, eps_iter, norm, iterations, second_attack_iters):\n",
    "    self.classifier = classifier\n",
    "    self.epsilon = epsilon\n",
    "    self.eps_iter = eps_iter\n",
    "    self.norm = norm\n",
    "    self.iterations = iterations\n",
    "    self.second_attack_iters = second_attack_iters\n",
    "\n",
    "  def init_attacker(self, attack_type, **kwargs):\n",
    "\n",
    "    if attack_type=='fast_gradient_method':\n",
    "        return FastGradientMethod(self.classifier,\n",
    "                                eps=self.epsilon,\n",
    "                                eps_step=self.eps_iter,\n",
    "                                minimal=True,\n",
    "                                norm=self.norm,\n",
    "                                **kwargs)\n",
    "    elif attack_type=='projected_gradient_descent':\n",
    "        return ProjectedGradientDescentPyTorch(self.classifier,\n",
    "                                             eps=self.epsilon,\n",
    "                                             eps_step=self.eps_iter,\n",
    "                                             max_iter=self.iterations,\n",
    "                                             norm=self.norm,\n",
    "                                             **kwargs)\n",
    "    elif attack_type=='auto_attack':\n",
    "        return AutoAttack(estimator=self.classifier,\n",
    "                        eps=self.epsilon,\n",
    "                        eps_step=self.eps_iter,\n",
    "                        norm=self.norm)\n",
    "    elif attack_type=='auto_projected_gradient_descent':\n",
    "        return AutoProjectedGradientDescent(estimator=self.classifier,\n",
    "                                          eps=self.epsilon,\n",
    "                                          eps_step=self.eps_iter,\n",
    "                                          norm=self.norm,\n",
    "                                          max_iter=self.iterations,\n",
    "                                          **kwargs)\n",
    "    elif attack_type=='auto_conjugate_gradient':\n",
    "        return AutoConjugateGradient(estimator=self.classifier,\n",
    "                                   eps=self.epsilon,\n",
    "                                   eps_step=self.eps_iter,\n",
    "                                   norm=self.norm,\n",
    "                                   max_iter=self.iterations,\n",
    "                                   **kwargs)\n",
    "    elif attack_type=='carlini_wagner_linf':\n",
    "        return CarliniLInfMethod(self.classifier,\n",
    "                               max_iter=self.second_attack_iters,\n",
    "                               **kwargs)\n",
    "    elif attack_type=='carlini_wagner_l2':\n",
    "        return CarliniL2Method(self.classifier,\n",
    "                               max_iter=self.second_attack_iters,\n",
    "                               **kwargs)\n",
    "    elif attack_type=='newton_fool':\n",
    "        return NewtonFool(self.classifier,\n",
    "                        max_iter=self.iterations,\n",
    "                        **kwargs)\n",
    "    elif attack_type=='deep_fool':\n",
    "        return DeepFool(self.classifier,\n",
    "                      max_iter=self.iterations,\n",
    "                      epsilon=self.eps_iter,\n",
    "                      **kwargs)\n",
    "    elif attack_type=='elastic_net':\n",
    "        return ElasticNet(self.classifier,\n",
    "                      max_iter=self.second_attack_iters)\n",
    "    elif attack_type=='frame_saliency':\n",
    "        attacker = BasicIterativeMethod(self.classifier,\n",
    "                                                 eps=self.epsilon,\n",
    "                                                 eps_step=self.eps_iter,\n",
    "                                                 max_iter=self.iterations,\n",
    "                                      )\n",
    "        return FrameSaliencyAttack(self.classifier,\n",
    "                                 attacker,\n",
    "                                 method='iterative_saliency')\n",
    "    elif attack_type=='hop_skip_jump':\n",
    "        return HopSkipJump(self.classifier,\n",
    "                         norm=self.norm,\n",
    "                         max_iter=self.second_attack_iters)\n",
    "    else:\n",
    "        raise ValueError(f'Attack type \"{attack_type}\" not supported!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adversarial Attack with Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-27T07:48:28.257899Z",
     "iopub.status.busy": "2024-05-27T07:48:28.256998Z",
     "iopub.status.idle": "2024-05-27T07:48:28.268387Z",
     "shell.execute_reply": "2024-05-27T07:48:28.267363Z",
     "shell.execute_reply.started": "2024-05-27T07:48:28.257864Z"
    }
   },
   "outputs": [],
   "source": [
    "def attack_with_early_stopping(classifier, x, y, max_iterations, attacker, verbose: bool = True):\n",
    "    label_flipped = False\n",
    "    count = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    x = x.unsqueeze(0).numpy()\n",
    "    y = y.numpy()\n",
    "\n",
    "    outputs = classifier.predict(x)\n",
    "    _, clean_predicted = torch.max(torch.tensor(outputs).data, 1)\n",
    "     \n",
    "    if clean_predicted.item()!=int(y):\n",
    "        print('Misclassified input. Not attacking.')\n",
    "        end_time = time.time()\n",
    "        return x, end_time - start_time\n",
    "\n",
    "    for i in range(max_iterations):\n",
    "\n",
    "        adv_inputs = attacker.generate(x, y=np.expand_dims(y, axis=0))\n",
    "\n",
    "        outputs = classifier.predict(adv_inputs)\n",
    "        _, predicted = torch.max(torch.tensor(outputs).data, 1)\n",
    "\n",
    "        label_flipped = bool(predicted.item()!=int(y))\n",
    "\n",
    "        if label_flipped:\n",
    "            if verbose:\n",
    "              print(f'\\nIterations for successful attack: {i+1}\\n')\n",
    "            break\n",
    "\n",
    "        x = adv_inputs.copy()\n",
    "    \n",
    "    end_time = time.time()\n",
    "    return adv_inputs, end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adversarial Distance calculation for adversarial attack methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-27T07:48:29.531789Z",
     "iopub.status.busy": "2024-05-27T07:48:29.531439Z",
     "iopub.status.idle": "2024-05-27T07:48:29.542783Z",
     "shell.execute_reply": "2024-05-27T07:48:29.541763Z",
     "shell.execute_reply.started": "2024-05-27T07:48:29.531760Z"
    }
   },
   "outputs": [],
   "source": [
    "def distance_calculation(classifier, x, y, epsilon, eps_iter, norm, max_iterations, attack_type, get_image: bool = False, verbose: bool = True):\n",
    "\n",
    "    distance_list, runtime_list = [], []\n",
    "\n",
    "    attacks = AdversarialAttacks(classifier=classifier,\n",
    "                          epsilon=epsilon,\n",
    "                          eps_iter=eps_iter,\n",
    "                          norm=norm,\n",
    "                          iterations=1,\n",
    "                          second_attack_iters=40)\n",
    "    attacker = attacks.init_attacker(attack_type)\n",
    "\n",
    "    correct_prediction = 0\n",
    "\n",
    "    for i, x in enumerate(xtest):\n",
    "        x_adversarial, runtime = attack_with_early_stopping(classifier=classifier,\n",
    "                                                            x=x,\n",
    "                                                            y=y[i],\n",
    "                                                            max_iterations=max_iterations,\n",
    "                                                            attacker=attacker)\n",
    "\n",
    "        x_adversarial_tensor = torch.from_numpy(x_adversarial)\n",
    "\n",
    "        # Adversarial accuracy calculation\n",
    "        output_adversarial = classifier.predict(x_adversarial)\n",
    "        _, predicted_adversarial = torch.max(torch.tensor(output_adversarial).data, 1)\n",
    "        correct_prediction += (predicted_adversarial.item() == int(y[i]))\n",
    "\n",
    "        distance = torch.norm((x - x_adversarial_tensor), p=float(norm))\n",
    "        distance_list.append(distance.item())\n",
    "        runtime_list.append(runtime)\n",
    "\n",
    "        if verbose:\n",
    "            print(f'Image {i}\\t\\tAdversarial_distance: {distance:.5f}\\t\\tRuntime: {runtime:5f} seconds')\n",
    "\n",
    "    if get_image:\n",
    "        get_example_image(x_adversarial, predicted_adversarial.item(), attack_type=attack_type)\n",
    "        get_example_image(x.unsqueeze(0).numpy(), y[i], attack_type='original')\n",
    "    \n",
    "    adversarial_accuracy = (correct_prediction / len(xtest)) * 100\n",
    "    print(f'\\nAdversarial accuracy: {adversarial_accuracy}%\\n')\n",
    "\n",
    "    return distance_list, runtime_list, adversarial_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate and Save Example Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-27T07:49:20.523208Z",
     "iopub.status.busy": "2024-05-27T07:49:20.522799Z",
     "iopub.status.idle": "2024-05-27T07:49:20.531187Z",
     "shell.execute_reply": "2024-05-27T07:49:20.530062Z",
     "shell.execute_reply.started": "2024-05-27T07:49:20.523175Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_example_image(x, y, attack_type: str):\n",
    "    label_map = {0: 'airplane',\n",
    "               1: 'automobile',\n",
    "               2: 'bird',\n",
    "               3: 'cat',\n",
    "               4: 'deer',\n",
    "               5: 'dog',\n",
    "               6: 'frog',\n",
    "               7: 'horse',\n",
    "               8: 'ship',\n",
    "               9: 'truck'}\n",
    "\n",
    "    img = x.squeeze(0).transpose(1, 2, 0)\n",
    "    img = Image.fromarray((img * 255).astype('uint8'), 'RGB')\n",
    "    img = img.resize((224, 224))\n",
    "\n",
    "    img = ImageOps.expand(img, border=10, fill=(255, 255, 255))\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    title = f'Label: {label_map[int(y)]}'\n",
    "    draw.text((0, 0), title, (0, 0, 0))\n",
    "\n",
    "    img.save(f'./data/example_image_{attack_type}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model configuration and Hyperparameter specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-27T07:52:00.434868Z",
     "iopub.status.busy": "2024-05-27T07:52:00.434438Z",
     "iopub.status.idle": "2024-05-27T07:52:00.445963Z",
     "shell.execute_reply": "2024-05-27T07:52:00.445071Z",
     "shell.execute_reply.started": "2024-05-27T07:52:00.434832Z"
    }
   },
   "outputs": [],
   "source": [
    "norm = 'inf'\n",
    "max_iterations = 500\n",
    "eps_iter_dict = {\n",
    "    'inf': 0.0003,\n",
    "    '1': 0.2,\n",
    "    '2': 0.005}\n",
    "eps_iter = eps_iter_dict[str(norm)]\n",
    "epsilon = max_iterations * eps_iter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load CIFAR-10 Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-27T07:52:40.388972Z",
     "iopub.status.busy": "2024-05-27T07:52:40.388061Z",
     "iopub.status.idle": "2024-05-27T07:52:41.103692Z",
     "shell.execute_reply": "2024-05-27T07:52:41.102672Z",
     "shell.execute_reply.started": "2024-05-27T07:52:40.388939Z"
    }
   },
   "outputs": [],
   "source": [
    "splitsize = 50\n",
    "xtest, ytest = load_dataset(dataset_split=splitsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-27T07:55:03.216296Z",
     "iopub.status.busy": "2024-05-27T07:55:03.215910Z",
     "iopub.status.idle": "2024-05-27T07:55:08.198621Z",
     "shell.execute_reply": "2024-05-27T07:55:08.197735Z",
     "shell.execute_reply.started": "2024-05-27T07:55:03.216264Z"
    }
   },
   "outputs": [],
   "source": [
    "attack_types = [\n",
    "                'fast_gradient_method',\n",
    "                'projected_gradient_descent',\n",
    "#                 'auto_projected_gradient_descent',\n",
    "#                 'auto_conjugate_gradient',\n",
    "                'newton_fool',\n",
    "                'deep_fool',\n",
    "#                 'elastic_net',\n",
    "#                 'frame_saliency',\n",
    "#                 'auto_attack',\n",
    "#                 'carlini_wagner_linf',\n",
    "#                 'carlini_wagner_l2',\n",
    "#                 'hop_skip_jump'\n",
    "                ]\n",
    "\n",
    "results_dict = {}\n",
    "\n",
    "for attack_type in attack_types:\n",
    "    results_dict[attack_type] = {}\n",
    "    print(f'\\t\\t-------------------------- Processing Attack: {attack_type} --------------------------\\n')\n",
    "    results_dict[attack_type][\"adversarial_distance\"], results_dict[attack_type][\"runtime\"], results_dict[attack_type][\"adversarial_accuracy\"] = distance_calculation(classifier=classifier,\n",
    "                                                        x=xtest,\n",
    "                                                        y=ytest,\n",
    "                                                        epsilon=epsilon,\n",
    "                                                        eps_iter=eps_iter,\n",
    "                                                        norm=norm,\n",
    "                                                        max_iterations=max_iterations,\n",
    "                                                        attack_type=attack_type)\n",
    "    \n",
    "    print(f'\\nMean adversarial distance for {attack_type}: {np.mean(results_dict[attack_type][\"adversarial_distance\"]):.5f} with total runtime: {sum(results_dict[attack_type][\"runtime\"]): .5f} seconds\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Results to JSON File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-27T07:57:04.366017Z",
     "iopub.status.busy": "2024-05-27T07:57:04.365174Z",
     "iopub.status.idle": "2024-05-27T07:57:04.372960Z",
     "shell.execute_reply": "2024-05-27T07:57:04.371991Z",
     "shell.execute_reply.started": "2024-05-27T07:57:04.365972Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "json_file_path = f'./data/attack_comparison_{modeltype}_L{norm}.json'\n",
    "\n",
    "with open(json_file_path, 'w') as f:\n",
    "    json.dump(results_dict, f, indent=4)\n",
    "print(f'Evaluation results are saved under \"{json_file_path}\".')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-27T07:57:13.843265Z",
     "iopub.status.busy": "2024-05-27T07:57:13.842846Z",
     "iopub.status.idle": "2024-05-27T07:57:13.847978Z",
     "shell.execute_reply": "2024-05-27T07:57:13.846924Z",
     "shell.execute_reply.started": "2024-05-27T07:57:13.843232Z"
    }
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(15, 8))\n",
    "# for attack_type in attack_types:\n",
    "#   plt.scatter(list(range(len(xtest))), results_dict[attack_type]['adversarial_distance'], label=attack_type)\n",
    "# plt.xlabel('Image ID ----->')\n",
    "# plt.ylabel('Distance ----->')\n",
    "# plt.title(f'L_{norm} Distance')\n",
    "# plt.legend()\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-27T07:57:20.925620Z",
     "iopub.status.busy": "2024-05-27T07:57:20.925275Z",
     "iopub.status.idle": "2024-05-27T07:57:20.929741Z",
     "shell.execute_reply": "2024-05-27T07:57:20.928825Z",
     "shell.execute_reply.started": "2024-05-27T07:57:20.925593Z"
    }
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(15, 8))\n",
    "# for attack_type in attack_types:\n",
    "#   plt.plot(list(range(len(xtest))), results_dict[attack_type]['runtime'], label=attack_type)\n",
    "# plt.xlabel('Image ID ----->')\n",
    "# plt.ylabel('Runtime [seconds] ----->')\n",
    "# plt.title('Step Runtime')\n",
    "# plt.legend()\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-27T07:57:25.572727Z",
     "iopub.status.busy": "2024-05-27T07:57:25.572131Z",
     "iopub.status.idle": "2024-05-27T07:57:25.576831Z",
     "shell.execute_reply": "2024-05-27T07:57:25.575907Z",
     "shell.execute_reply.started": "2024-05-27T07:57:25.572693Z"
    }
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(15, 8))\n",
    "# for attack_type in attack_types:\n",
    "#   plt.bar(attack_type, results_dict[attack_type]['adversarial_accuracy'], label=attack_type)\n",
    "# plt.xlabel('Attacks')\n",
    "# plt.ylabel('Adversarial accuracy [%] ----->')\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.legend()\n",
    "# plt.title('Adversarial Accuracy')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-27T07:57:32.014889Z",
     "iopub.status.busy": "2024-05-27T07:57:32.014185Z",
     "iopub.status.idle": "2024-05-27T07:57:32.019079Z",
     "shell.execute_reply": "2024-05-27T07:57:32.018127Z",
     "shell.execute_reply.started": "2024-05-27T07:57:32.014857Z"
    }
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(15, 8))\n",
    "# for attack_type in attack_types:\n",
    "#   plt.bar(attack_type, sum(results_dict[attack_type]['runtime']), label=attack_type)\n",
    "# plt.xlabel('Attacks')\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.ylabel('Runtime [seconds]----->')\n",
    "# plt.title('Total Runtime')\n",
    "# plt.legend()\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 47677,
     "sourceId": 56827,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
