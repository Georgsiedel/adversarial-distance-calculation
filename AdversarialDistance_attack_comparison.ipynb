{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Installation and Repository cloning","metadata":{}},{"cell_type":"code","source":"!pip install adversarial-robustness-toolbox -U --quiet\n!pip install multiprocess --quiet\n!pip install importlib --quiet\n!pip install advertorch --quiet\n!git clone https://github.com/Georgsiedel/adversarial-distance-estimation.git\n!pip install git+https://github.com/RobustBench/robustbench.git","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import Libraries","metadata":{}},{"cell_type":"code","source":"import torch\nimport torchvision\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms, models\nfrom advertorch_examples.models import get_cifar10_wrn28_widen_factor\n\nimport numba\nnumba.__version__\n\nimport importlib\nimport time\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom art.estimators.classification import PyTorchClassifier\nfrom PIL import Image, ImageDraw, ImageFont, ImageOps\nfrom robustbench.utils import load_model\nimport json","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load and Prepare CIFAR-10 Dataset","metadata":{}},{"cell_type":"code","source":"def load_dataset(dataset_split):\n    # Load CIFAR-10 dataset using torchvision\n    transform = transforms.Compose([\n      transforms.ToTensor(),\n                                 ])\n    testset = datasets.CIFAR10(root='./data/cifar', train=False, download=True, transform=transform)\n\n    # Truncated testset for experiments and ablations\n    if isinstance(dataset_split, int):\n        testset, _ = torch.utils.data.random_split(testset,\n                                                          [dataset_split, len(testset) - dataset_split],\n                                                          generator=torch.Generator().manual_seed(42))\n    \n    # Extract data and labels from torchvision dataset\n    xtest = torch.stack([data[0] for data in testset])\n    ytest = torch.tensor([data[1] for data in testset])\n\n    return xtest, ytest","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load and Prepare WideResNet Model","metadata":{}},{"cell_type":"code","source":"%cd /kaggle/working/adversarial-distance-estimation\nimport models.wideresnet as wideresnet\n# %cd\n\nmodeltype = 'adversarial'\n\nprint(f'\\nLoading {modeltype} Model...\\n')\nif modeltype == 'standard':\n    net = wideresnet.WideResNet_28_4(10, 'CIFAR10', normalized=True, block=wideresnet.WideBasic, activation_function='relu')\n    state_dict = \"model_state_dict\"\n    net = torch.nn.DataParallel(net)\n    PATH = f'./models/pretrained_models/{modeltype}.pth'\n    model = torch.load(PATH)\n    net.load_state_dict(model[state_dict], strict=False)\nelif modeltype == 'robust':\n    #self trained with massive random data augmentation and JSD consistency loss, but no adversarial objective\n    net = wideresnet.WideResNet_28_4(10, 'CIFAR10', normalized=True, block=wideresnet.WideBasic, activation_function='silu')\n    net = torch.nn.DataParallel(net)\n    state_dict = \"model_state_dict\"\n    PATH = f'./models/pretrained_models/{modeltype}.pth'\n    model = torch.load(PATH)\n    net.load_state_dict(model[state_dict], strict=False)\nelif modeltype == 'adversarial':\n    #from https://github.com/BorealisAI/mma_training/tree/master/trained_models/cifar10-Linf-MMA-20-sd0\n    model_name = 'Ding2020MMA'\n    net = load_model(model_name=model_name, dataset='cifar10', threat_model='Linf')\n    net = torch.nn.DataParallel(net)\n\n%cd\nnet.eval()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Function to Test Model Accuracy","metadata":{}},{"cell_type":"code","source":"def test_accuracy(model, xtest, ytest):\n    model.eval()\n    correct, total = 0, 0\n\n    with torch.no_grad():\n        for i in range(len(xtest)):\n            x = xtest[i].unsqueeze(0).to(device)\n            y = ytest[i].unsqueeze(0).to(device)\n\n            outputs = model(x)\n            _, predicted = torch.max(outputs.data, 1)\n\n            total += y.size(0)\n            correct += (predicted==y).sum().item()\n\n    accuracy = (correct / total) * 100\n    print(f'\\nAccuracy of the testset is: {accuracy:.3f}%\\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(net.parameters(), lr=0.01)\n\n# Initialize PyTorchClassifier for ART\nclassifier = PyTorchClassifier(model=net,\n                               loss=criterion,\n                               optimizer=optimizer,\n                               input_shape=(3, 32, 32),\n                               nb_classes=10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from art.attacks.evasion import (FastGradientMethod,\n                                 ProjectedGradientDescentNumpy,\n                                 AutoAttack,\n                                 AutoProjectedGradientDescent,\n                                 AutoConjugateGradient,\n                                 CarliniLInfMethod,\n                                 CarliniL2Method,\n                                 NewtonFool,\n                                 DeepFool,\n                                 ElasticNet,\n                                 FrameSaliencyAttack,\n                                 HopSkipJump,\n                                 BasicIterativeMethod)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Adversarial Attack Class","metadata":{}},{"cell_type":"code","source":"class AdversarialAttacks:\n  def __init__(self, classifier, epsilon, eps_iter, norm, iterations, second_attack_iters):\n    self.classifier = classifier\n    self.epsilon = epsilon\n    self.eps_iter = eps_iter\n    self.norm = norm\n    self.iterations = iterations\n    self.second_attack_iters = second_attack_iters\n\n  def init_attacker(self, attack_type, **kwargs):\n    if attack_type=='fast_gradient_method':\n        return FastGradientMethod(self.classifier,\n                                eps=self.epsilon,\n                                eps_step=self.eps_iter,\n                                minimal=True,\n                                norm=self.norm,\n                                **kwargs)\n    elif attack_type=='projected_gradient_descent':\n        return ProjectedGradientDescentNumpy(self.classifier,\n                                             eps=self.epsilon,\n                                             eps_step=self.eps_iter,\n                                             max_iter=self.iterations,\n                                             norm=self.norm,\n                                             **kwargs)\n    elif attack_type=='auto_attack':\n        return AutoAttack(estimator=self.classifier,\n                        eps=self.epsilon,\n                        eps_step=self.eps_iter,\n                        norm=self.norm)\n    elif attack_type=='auto_projected_gradient_descent':\n        return AutoProjectedGradientDescent(estimator=self.classifier,\n                                          eps=self.epsilon,\n                                          eps_step=self.eps_iter,\n                                          norm=self.norm,\n                                          max_iter=self.iterations,\n                                          **kwargs)\n    elif attack_type=='auto_conjugate_gradient':\n        return AutoConjugateGradient(estimator=self.classifier,\n                                   eps=self.epsilon,\n                                   eps_step=self.eps_iter,\n                                   norm=self.norm,\n                                   max_iter=self.iterations,\n                                   **kwargs)\n    elif attack_type=='carlini_wagner_linf':\n        return CarliniLInfMethod(self.classifier,\n                               max_iter=self.second_attack_iters,\n                               **kwargs)\n    elif attack_type=='carlini_wagner_l2':\n        return CarliniL2Method(self.classifier,\n                               max_iter=self.second_attack_iters,\n                               **kwargs)\n    elif attack_type=='newton_fool':\n        return NewtonFool(self.classifier,\n                        max_iter=self.iterations,\n                        **kwargs)\n    elif attack_type=='deep_fool':\n        return DeepFool(self.classifier,\n                      max_iter=self.iterations,\n                      epsilon=self.eps_iter,\n                      **kwargs)\n    elif attack_type=='elastic_net':\n        return ElasticNet(self.classifier,\n                      max_iter=self.second_attack_iters)\n    elif attack_type=='frame_saliency':\n        attacker = BasicIterativeMethod(self.classifier,\n                                                 eps=self.epsilon,\n                                                 eps_step=self.eps_iter,\n                                                 max_iter=self.iterations,\n                                      )\n        return FrameSaliencyAttack(self.classifier,\n                                 attacker,\n                                 method='iterative_saliency')\n    elif attack_type=='hop_skip_jump':\n        return HopSkipJump(self.classifier,\n                         norm=self.norm,\n                         max_iter=self.second_attack_iters)\n    else:\n        raise ValueError(f'Attack type \"{attack_type}\" not supported!')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plug-in Function for Adversarial Attack with Early Stopping","metadata":{}},{"cell_type":"code","source":"def attack_with_early_stopping(classifier, x, y, max_iterations, attacker):\n    label_flipped = False\n    count = 0\n    start_time = time.time()\n\n    x = x.unsqueeze(0)\n\n    outputs = classifier.predict(x.cpu().numpy())\n    _, clean_predicted = torch.max(torch.tensor(outputs).to(device).data, 1)\n    \n    if int(clean_predicted.item()) != int(y.item()):\n        print('Misclassified input. Not attacking.')\n        end_time = time.time()\n        return x.cpu().detach().numpy(), end_time - start_time, 0\n\n    for j in range(max_iterations):\n        adv_inputs = attacker.generate(x.cpu().detach().numpy(), y.cpu().detach().numpy())\n\n        adv_inputs_tensor = torch.from_numpy(adv_inputs).to(device)\n        outputs = classifier.predict(adv_inputs)\n        _, predicted = torch.max(torch.tensor(outputs).to(device).data, 1)\n\n        label_flipped = bool(predicted.item() != int(y.item()))\n\n        if label_flipped:\n            print(f'\\tIterations for successful iterative attack: {j+1}')\n            break\n            \n        x = adv_inputs_tensor.clone()\n\n    end_time = time.time()\n    return adv_inputs, end_time - start_time, j","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Function for Adversarial Distance calculation (attack methods)","metadata":{}},{"cell_type":"code","source":"def distance_calculation(classifier, xtest, ytest, epsilon, eps_iter, norm, max_iterations, attack_type, get_image: bool = False, verbose: bool = True):\n\n    distance_list, runtime_list = [], []\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    classifier.model.to(device)\n    xtest = xtest.to(device)\n    ytest = ytest.to(device)\n    \n    attacks = AdversarialAttacks(classifier=classifier,\n                          epsilon=epsilon,\n                          eps_iter=eps_iter,\n                          norm=norm,\n                          iterations=1,\n                          second_attack_iters=40)\n    attacker = attacks.init_attacker(attack_type)\n\n    correct_prediction = 0\n\n    for i, x in enumerate(xtest):\n        x = x.to(device)\n        y = ytest[i].unsqueeze(0).to(device)\n        \n        x_adversarial, runtime, iterations = attack_with_early_stopping(classifier=classifier,\n                                                            x=x,\n                                                            y=y,\n                                                            max_iterations=max_iterations,\n                                                            attacker=attacker)\n\n        x_adversarial_tensor = torch.from_numpy(x_adversarial).to(device)\n\n        # Adversarial accuracy calculation\n        output_adversarial = classifier.predict(x_adversarial)\n        _, predicted_adversarial = torch.max(torch.tensor(output_adversarial).to(device).data, 1)\n        correct_prediction += (predicted_adversarial.item() == int(y.item()))\n\n        distance = torch.norm((x - x_adversarial_tensor), p=float(norm))\n        if distance.item() == 0.0:\n            distance_list.append(0.0)\n            print(f'\\nMisclassified!!! dist: {distance.item()}\\n')\n        else:\n            distance_list.append(distance.item())\n        runtime_list.append(runtime)\n\n        if verbose:\n            print(f'Image {i}\\t\\tAdversarial_distance: {distance:.5f}\\t\\tRuntime: {runtime:5f} seconds')\n\n    if get_image:\n        get_example_image(x_adversarial, predicted_adversarial.item(), attack_type=attack_type)\n        get_example_image(x.unsqueeze(0).numpy(), y[i], attack_type='original')\n    \n    adversarial_accuracy = (correct_prediction / len(xtest)) * 100\n    print(f'\\nAdversarial accuracy: {adversarial_accuracy}%\\n')\n\n    return distance_list, runtime_list, adversarial_accuracy","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Parameters","metadata":{}},{"cell_type":"code","source":"norm = np.inf  # 1, 2, np.inf\nmax_iterations = 500\neps_iter_dict = {\n    'inf': 0.0003,\n    '1': 0.2,\n    '2': 0.005}\neps_iter = eps_iter_dict[str(norm)]\nepsilon = max_iterations * eps_iter","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load the dataset","metadata":{}},{"cell_type":"code","source":"splitsize = 'full'        # full, int: splitsize\nxtest, ytest = load_dataset(dataset_split=splitsize)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Test Accuracy","metadata":{}},{"cell_type":"code","source":"test_accuracy(net, xtest, ytest)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Experiments","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"attack_types = [\n                'fast_gradient_method',\n                'projected_gradient_descent',\n                'auto_projected_gradient_descent',\n                'auto_conjugate_gradient',\n                'newton_fool',\n                'deep_fool',\n                'elastic_net',\n                'frame_saliency',\n                'auto_attack',\n                'carlini_wagner_linf',\n                'carlini_wagner_l2',\n                'hop_skip_jump'\n                ]\n\nresults_dict = {}\n\nfor attack_type in attack_types:\n    results_dict[attack_type] = {}\n    print(f'\\t\\t-------------------------- Processing Attack: {attack_type} --------------------------\\n')\n    results_dict[attack_type][\"adversarial_distance\"], results_dict[attack_type][\"runtime\"], results_dict[attack_type][\"adversarial_accuracy\"] = distance_calculation(classifier=classifier,\n                                                        xtest=xtest,\n                                                        ytest=ytest,\n                                                        epsilon=epsilon,\n                                                        eps_iter=eps_iter,\n                                                        norm=norm,\n                                                        max_iterations=max_iterations,\n                                                        attack_type=attack_type)\n    \n    mean_value = np.mean([x for x in results_dict[attack_type][\"adversarial_distance\"] if x is not None])\n\n    print(f'\\nMean adversarial distance for {attack_type}: {mean_value:.5f} with total runtime: {sum(results_dict[attack_type][\"runtime\"]): .5f} seconds\\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Save Results to JSON File","metadata":{}},{"cell_type":"code","source":"json_file_path = f'./data/attack_comparison_{modeltype}_L{norm}.json'\n\nwith open(json_file_path, 'w') as f:\n    json.dump(results_dict, f, indent=4)\nprint(f'Evaluation results are saved under \"{json_file_path}\".')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Plotting","metadata":{}},{"cell_type":"markdown","source":"## Distances","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(16, 6))\nfor attack_type in attack_types:\n  plt.scatter(list(range(len(xtest))), results_dict[attack_type]['adversarial_distance'], label=attack_type)\nplt.xlabel('Image ID ----->')\nplt.ylabel('Distance ----->')\nplt.title(f'L{norm} Distance')\nplt.legend()\nplt.tight_layout()\nplt.xticks(list(range(len(xtest))))\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15, 8))\nfor attack_type in attack_types:\n  plt.plot(list(range(len(xtest))), results_dict[attack_type]['adversarial_distance'], label=attack_type)\nplt.xlabel('Image ID')\nplt.ylabel('Distance')\nplt.title(f'L{norm} Distance')\nplt.legend()\nplt.tight_layout()\nplt.xticks(list(range(len(xtest))))\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Runtime per image","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15, 8))\nfor attack_type in attack_types:\n  plt.plot(list(range(len(xtest))), results_dict[attack_type]['runtime'], label=attack_type)\nplt.xlabel('Image ID')\nplt.ylabel('Runtime [seconds]')\nplt.title('Step Runtime')\nplt.legend()\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Adversarial Accuracy","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15, 8))\nfor attack_type in attack_types:\n  plt.bar(attack_type, results_dict[attack_type]['adversarial_accuracy'], label=attack_type)\nplt.xlabel('Attacks')\nplt.ylabel('Adversarial accuracy [%]')\nplt.xticks(rotation=45)\nplt.legend()\nplt.title('Adversarial Accuracy')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Total Runtime","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15, 8))\nfor attack_type in attack_types:\n  plt.bar(attack_type, sum(results_dict[attack_type]['runtime']), label=attack_type)\nplt.xlabel('Attacks')\nplt.xticks(rotation=45)\nplt.ylabel('Runtime [seconds]')\nplt.title('Total Runtime')\nplt.legend()\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}